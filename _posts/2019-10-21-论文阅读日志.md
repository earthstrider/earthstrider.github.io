---
layout:     post
title:      论文阅读日志
subtitle:   
date:       2019-10-24
author:     猫不见了
comments:	true
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - Paper
---

[TOC]

## 2019.10.21

#### Test set leakage是什么问题？有多严重？

WN18（以及FB15k） 的测试集与训练集存在逆关系，这个规律被人发现并很严重，导致使用简单的基于规则的模型就能实现state-of-the-art结果。



#### Link Prediction研究的问题是什么？

举个简单的例子，Freebase和DBpedia中超过66%的人物实体缺少出生日期，如何识别或预测缺失的出生日期就是Link Prediction问题。真实应用场景，需要考虑Link Prediction算法在大规模数据上运行的效率，参数数据和计算成本都需可控。



#### 已有的方法有哪些？

已有的工作关注可以扩展到大规模知识图上的浅层，快速模型。模型由简单的操作组成，在有限参数的嵌入空间上进行内积，或矩阵乘法操作。



缺点：

1. 只能通过增加向量维度的方式来增加特征数量；

2. 如果使用多层特征，即多层知识图嵌入，容易过拟合。

   

解决办法：

使用参数有效的，快速的操作符，其可以构成深层结构网络。



模型：

TransE 2013

DistMult 2015

ComplEx 2016



HolE 2016



this model is characterised by **three-way interactions** between embedding parameters？加粗地方什么意思？



#### 还可以使用多层特征？



#### 文中提出的ConvE如何架构，为什么就可以避免缺点1和缺点2？



#### 什么是1-N评分程序？



#### 为什么使用二维卷积，而不是一维卷积？





## 2019.10.22

#### 作者提出的编码器为什么能够获得更多的特征？

编码器由卷积层，融合层，dense block组成。



#### 已有哪些方法提取图像显著特征？

muli-scale decomposition-based methods，基于多尺度分解的方法，灵感来自信号处理的方法。

表示学习方法，稀疏领域：sparse representation(SR)，HOG，joint sparse representation(JSR)，co-spase representation；低秩领域：基于低秩表示融合方法。



缺点：

基于CNN的融合方法，仅仅最后一层的特征信息被利用，中间层的特征信息被忽略。



#### 作者提出的网络如何架构？

编码网络提取图片特征，解码网络获得融合图像。



编码网络由卷积层和dense block组成。

解码网络由四层卷积神经网络组成。



编码网络每一层的结果被解码网络利用，融合图像将由融合策略和解码网络生成。



#### 为什么要将红外图像和可视图像融合？为什么会有这个需求？

举个例子，监控相机白天可以拍摄出清晰的可视图像，而夜间只能通过红外获得黑白图像，如何获得高质量的夜间图像就是要解决的问题。



#### 输入图像配准什么意思？

Image registration is the process of finding the optimal alignment between images.



#### 融合层在哪，在哪？

融合层不是网络的一部分，仅仅是利用编码器的输出，结合融合策略，生成最终的融合图像。



#### 哪两种融合策略？巧妙之处在哪？



1. addition strategy

2. $$l_1-norm$$ strategy

   

#### multi-temporal遥感图像什么意思？

多时相遥感：利用不同时间所获取的同一地域图像，提取目标动态变化信息的遥感。



#### 图像和图片的区别？



#### 红外图像是黑白的吗？有哪些特点？

主动红外摄像技术是利用特制的“红外灯”人为产生红外辐射，发出红外光去照射物体，利用成像元件（CCD或CMOS）去感受周围环境反射回来的红外光，从而实现夜视功能。



#### SSIM指标如何计算？

SSIM是用来测量两个图片的相似性。



#### __future__是一个包？有什么用？



#### 什么是soft-max？





#### ResNet解决了什么问题？



#### 根据层输入将层重新表示为学习残差函数什么意思？



#### 为什么使用ReLU作为激活函数？

ReLU的使用，使得网络可以自行引入稀疏性，同时大大提高训练速度。



<img src="http://ddrvcn.oss-cn-hangzhou.aliyuncs.com/2019/5/NRnQ32.png"  width=70%/>



#### 网络稀疏性是指什么？稀疏性有什么作用？

参数中零的个数越多，网络越稀疏。



1. 特征选择
2. 可解释性

> https://blog.csdn.net/a362682954/article/details/85226022



#### BATCH_SIZE是什么？EPOCHES？





## 2019.10.24

